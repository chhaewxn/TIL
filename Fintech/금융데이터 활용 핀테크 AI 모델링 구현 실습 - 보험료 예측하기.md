## ğŸ“ ê¸ˆìœµë°ì´í„° í™œìš© í•€í…Œí¬ AI ëª¨ë¸ë§ êµ¬í˜„ ì‹¤ìŠµ - ë³´í—˜ë£Œ ì˜ˆì¸¡í•˜ê¸°

### ë‹¤ì¤‘íšŒê·€ ëª¨í˜•
- ì•ì˜ ì˜ˆì œë“¤ì€ ë¬¼ê³ ê¸°ì˜ ë„ˆë¹„, ê¸¸ì´ë§Œ ê³ ë ¤í–ˆìœ¼ë‚˜, ì´ë²ˆì—ëŠ” ë¬¼ê³ ê¸°ì˜ ë‘ê»˜ê¹Œì§€ ê³ ë ¤í•œë‹¤,
- ë³€ìˆ˜(íŠ¹ì„±)ì„ ì¶”ê°€í•˜ê³ , ê°ê° ì œê³±í•´ì„œ ìƒˆë¡œìš´ íŠ¹ì„±ì„ ë§Œë“ ë‹¤. ì´ëŸ¬í•œ íŠ¹ì„±ì„ ë½‘ì•„ë‚´ëŠ” ì‘ì—…ì„ 'íŠ¹ì„±ê³µí•™'ì´ë¼ê³  í•¨.

```python
import pandas as pd

df = pd.read_csv('https://bit.ly/perch_csv_data')
perch_full = df.to_numpy()
print(perch_full)

import numpy as np

perch_weight = np.array(
    [5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0,
     110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0,
     130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0,
     197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0,
     514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0,
     820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0,
     1000.0, 1000.0]
     
from sklearn.model_selection import train_test_split

train_input, test_input, train_target, test_target = train_test_split(perch_full, perch_weight, random_state=42)
     )
```
![](https://velog.velcdn.com/images/chhaewxn/post/7959bbd2-95c2-44a1-8cde-0fc5f898493c/image.png)

### ì‚¬ì´í‚·ëŸ° ë³€í™˜ê¸°
Scikit-Learnì€ ì‚¬ìš©ì´ ê°„í¸í•˜ê³  ì¼ê´€ëœ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•˜ì—¬, ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜ì„ íš¨ê³¼ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê³  ëª¨ë¸ì„ êµ¬ì¶•í•˜ë©° í‰ê°€í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬

## ì‹¤ìŠµ - ë³´í—˜ë£Œ ì˜ˆì¸¡
### 0. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° 
```python
import pandas as pd

insurance = pd.read_csv('https://raw.githubusercontent.com/fintech-data/Revolution/main/data/insurance.csv')
insurance.head()
```

### 1. ë°ì´í„° ì „ì²˜ë¦¬
```python
insurance.shape
insurance.info()
```

#### 1-1. ê²°ì¸¡ì¹˜ ì œê±° 
```python
# ê²°ì¸¡ì¹˜ ì—†ìŒ
insurance.isnull().sum()
```

#### 1-2. ì´ìƒì¹˜ íƒì§€
```python
insurance.describe()

import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.patheffects as path_effects
%matplotlib inline

bplot= sns.boxplot(data=insurance)
# chargesì˜ ê°’ì´ ë„ˆë¬´ ì»¤ì„œ ë‚˜ë¨¸ì§€ ê°’ë“¤ì´ ì œëŒ€ë¡œ ë³´ì´ì§€ ì•Šìœ¼ë¯€ë¡œ í•˜ë‚˜í•˜ë‚˜ ê·¸ë ¤ë³´ì
```
![](https://velog.velcdn.com/images/chhaewxn/post/6f424897-623e-4b32-9649-515bbec47a25/image.png)

```python
insurance.head()
bplot= sns.boxplot(data= insurance[['age', 'bmi']])
bplot= sns.boxplot(data= insurance[['children']])
bplot= sns.boxplot(data= insurance[['charges']])
```
![](https://velog.velcdn.com/images/chhaewxn/post/6af5fa77-e195-40aa-b6b0-ecd5efe8c984/image.png)
![](https://velog.velcdn.com/images/chhaewxn/post/e7114fe9-b7c8-41e8-927f-fa549142cef2/image.png)
![](https://velog.velcdn.com/images/chhaewxn/post/3a0b15af-8469-4e24-9f3f-525f85b11799/image.png)

### ê²°ë¡  : chargesì™€ BMIì— ì´ìƒì¹˜ ê°’ë“¤ì´ ìˆëŠ” ê²ƒì„ í™•ì¸

- ê¸°ë³¸ :  x < Q1 - IQR or X > Q3 + IQR ê°’ë“¤ì„ ì œê±°
- ë°ì´í„°ì— ë”°ë¼ ì´ìƒì¹˜ê°€ í•„ìš”í•˜ë‹¤ê³  íŒë‹¨í•˜ì—¬ ì œê±°í•˜ì§€ ì•ŠëŠ” ê²½ìš°ë„ ìˆìŒ
- ë³´í—˜ì˜ ê²½ìš° ì´ìƒì¹˜ê°€ ìˆëŠ” ë°ì´í„°ê°€ í•„ìš”í•˜ê¸°ì— ì´ìƒì¹˜ë¥¼ ì œê±°í•˜ì§€ ì•Šê³  ë¡œê·¸ë³€í™˜ì„ í†µí•´ ì¼ì •ë¶€ë¶„ í•´ê²°í•˜ì

### 2. íƒìƒ‰ì  ìë£Œë¶„ì„(EDA)
#### 2-1. ë²”ì£¼í˜•

```python
insurance.head()
insurance['sex'].value_counts().plot.bar()
insurance['children'].value_counts().plot.bar()
insurance['smoker'].value_counts().plot.bar()
insurance['region'].value_counts().plot.bar()
```

#### 2-2. ë²”ì£¼í˜• ë³€ìˆ˜ì™€ yì™€ì˜ ê´€ê³„
- ë²”ì£¼í˜• & ì—°ì†í˜• : bar plot, box plot ë“± 

```python
# ë‚¨ì„±ì¼ìˆ˜ë¡ ë³´í—˜ë£Œê°€ ë¹„ì‹¸ë‹¤
sns.barplot(x='sex', y='charges', data=insurance)

# ìë…€ì— ë”°ë¥¸ ë³´í˜ë£Œì˜ ì°¨ì´ëŠ” ë¯¸ë¹„í•˜ë‚˜ 2~3ëª…ì¼ ê²½ìš° ë³´í—˜ë£Œê°€ ê°€ì¥ ë¹„ì‹¸ë‹¤.
sns.barplot(x='children', y='charges', data=insurance)

# Q. 5ëª…ì¼ ë•Œ íŠ¹íˆ ë³´í—˜ë£Œê°€ ì‘ê²Œ ë‚˜ì˜¨ë‹¤ -> ì´ëŠ” ë°ì´í„° ìì²´ê°€ ì‘ì•„ì„œì´ë‹¤. ìœ„ì˜ bar plotìœ¼ë¡œë„ í™•ì¸ ê°€ëŠ¥

#ìë…€ìˆ˜ê°€ 4, 5ì¼ ë•Œ ë°ì´í„°ê°€ ì ë‹¤.
insurance['children'].value_counts()

# regionì— ì˜í•œ ì°¨ì´ëŠ” ë¯¸ë¹„í•˜ë‹¤ ë‚¨ë™ìª½ì´ ë‹¤ë¥¸ ì§€ì—­ì— ë¹„í•´ ë³´í—˜ë£Œê°€ ë¹„ì‹¸ë‹¤
sns.barplot(x='region', y='charges', data=insurance)
```
![](https://velog.velcdn.com/images/chhaewxn/post/cde365f3-ba85-41e8-bf5d-b77232e2e0e2/image.png)

#### ê°€ì„¤ 1. ë‚¨ë™ë¶€ ì§€ì—­ì˜ BMIê°€ ë” ë†’ë‹¤
- í™•ì¸: boxplot ê·¸ë¦¬ì
```python
bplot= sns.boxplot(y = 'bmi', x= 'region', data = insurance)

# ì‹¤ì œë¡œ ë‚¨ë™ìª½ì˜ BMIê°€ ë” ë†’ì€ê²ƒì„ í™•ì¸ í•  ìˆ˜ìˆë‹¤.
# ê°€ì„¤ ì„±ë¦½!
```

### 2-3. ì—°ì†í˜•

```python
import warnings
warnings.filterwarnings('ignore')

# 20ëŒ€ê°€ ê°€ì¥ ë§ë‹¤
sns.distplot(insurance['age'])

# ì •ê·œë¶„í¬ ëª¨í˜•ì„ ë„ë©° bmi 30~35 ì‚¬ì´ê°€ ê°€ì¥ ë§ë‹¤.
sns.distplot(insurance['bmi'])

# ì¢…ì†ë³€ìˆ˜ y : ì˜¤ë¥¸ìª½ìœ¼ë¡œ ê¼¬ë¦¬ê°€ ê¸¸ë‹¤ -> log ë³€í™˜
sns.distplot(insurance['charges'])


import numpy as np
# ì¢…ì†ë³€ìˆ˜ y : ì˜¤ë¥¸ìª½ìœ¼ë¡œ ê¼¬ë¦¬ê°€ ê¸¸ë‹¤ -> log ë³€í™˜ -> ê¼¬ë¦¬ê°€ ì‚¬ë¼ì§
sns.distplot(np.log(insurance['charges']))
# y -> log(y)ë¥¼ ì‚¬ìš©í•˜ì—¬ íšŒê·€ë¶„ì„

```
![](https://velog.velcdn.com/images/chhaewxn/post/60e158d8-ecea-4bc4-8c71-329a66c423d1/image.png)

### 2-4. ì—°ì†í˜• & ì¢…ì†ë³€ìˆ˜ì™€ì˜ ê´€ê³„
- ì—°ì†í˜• & ì—°ì†í˜• : ìƒê´€ê´€ê³„
```python
corr = insurance.corr(method = 'pearson')
corr

df_heatmap = sns.heatmap(corr, cbar = True, annot = True, annot_kws={'size' : 20}, fmt = '.2f', square = True, cmap = 'Greens')

# ì¢…ì†ë³€ìˆ˜(ë³´í—˜ë£Œ)ì™€ì˜ ìƒê´€ê´€ê³„ì˜ ê²½ìš°, ë‚˜ì´ > BMI ìˆœìœ¼ë¡œ ìƒê´€ê´€ê³„ê°€ ë†’ì€ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤
```

### 3. ëª¨ë¸ë§
- íšŒê·€ ì˜ˆì¸¡ ëª¨ë¸ë§ : Regression, RandomForest, SVM

#### 3-1. íšŒê·€ë¶„ì„
```python
from sklearn.linear_model import LinearRegression

insurance_data = pd.get_dummies(insurance)
# ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ì´ì§„ í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ì›-í•« ì¸ì½”ë”© ë§ì´ ì‚¬ìš©ë¨

X= insurance_data[['age', 'bmi', 'children', 'sex_female', 'sex_male',
       'smoker_no', 'smoker_yes', 'region_northeast', 'region_northwest',
       'region_southeast', 'region_southwest']]
y = np.log(insurance_data['charges'])

from numpy import log as ln
x=ln(10) # íŒŒì´ì¬ì—ì„œ log -> lnë¡œê·¸ë¡œ ë¼ ìˆì–´ì„œ, lnì„ ì§€ìˆ˜ log10ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì´ í•„ìš”

insurance_data["sex_male"]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=30)

# ë‹¨ìˆœíšŒê·€ë¶„ì„ ëª¨í˜• ê°ì²´ ìƒì„±
lr = LinearRegression()
lr.fit(X_train, y_train)

# trainì˜ R^2 ê°’
lr.score(X_train, y_train)

# testì˜ R^2 ê°’
lr.score(X_test, y_test)

y_predict = lr.predict(X_test)

plt.scatter(y_test, y_predict, alpha=0.4)
plt.xlabel("Actual Value")
plt.ylabel("Predicted Value")
plt.title("MULTIPLE LINEAR REGRESSION")
plt.show()

y1 = insurance_data['charges']

from sklearn.model_selection import train_test_split
X_train, X_test, y1_train, y1_test = train_test_split(X, y1, test_size=0.30, random_state=30)
                           
# ë‹¨ìˆœíšŒê·€ë¶„ì„ ëª¨í˜• ê°ì²´ ìƒì„±
lr = LinearRegression()
lr.fit(X_train, y1_train)

# trainì˜ R^2 ê°’
lr.score(X_train, y1_train)

lr.score(X_test, y1_test)

```

![](https://velog.velcdn.com/images/chhaewxn/post/585241a8-fe81-4847-8e90-9a5dc8421b0d/image.png)

![](https://velog.velcdn.com/images/chhaewxn/post/5e6753e8-4e7e-4ab1-b27e-7c49a7b9ba09/image.png)


**+ ê·¼ì ‘íšŒê·€ ëª¨ë¸ ë§Œë“¤ê¸°**

```python
from sklearn.neighbors import KNeighborsRegressor

knr = KNeighborsRegressor()

knr.fit(X_train, y_train)

print(knr.score(X_test, y_test))
```
â¡ï¸ ê²°ê³¼ í™•ì¸í•´ë³´ë©´, ì•½ 0.3644 ë¡œ ì •í™•ë„ê°€ ë–¨ì–´ì§€ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŒ

### 3-1-1. ë¹„ì„ í˜• íšŒê·€

```python
from sklearn.preprocessing import PolynomialFeatures
poly_features = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly_features.fit_transform(X_train)

lin_reg = LinearRegression()
lin_reg.fit(X_poly, y_train)

lin_reg.score(X_poly, y_train)

lin_reg.intercept_, lin_reg.coef_
X_test_poly = poly_features.transform(X_test)
y_predict = lin_reg.predict(X_test_poly)

plt.scatter(y_test, y_predict, alpha=0.4)
plt.xlabel("Actual Value")
plt.ylabel("Predicted Value")
plt.title("MULTIPLE LINEAR REGRESSION")
plt.show()
```

**â• ëª¨ë¸ í‰ê°€ ì§€í‘œ RMSE **

![](https://velog.velcdn.com/images/chhaewxn/post/b0f0ce4b-d63e-4fd9-8fd7-85a7d6909c22/image.png)

- íšŒê·€ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ëŒ€í‘œì ì¸ í‰ê°€ ì§€í‘œ ì¤‘ í•˜ë‚˜ 
- RMSEëŠ” ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê°’ê³¼ ì‹¤ì œ ê´€ì¸¡ê°’ ê°„ì˜ ì°¨ì´ë¥¼ í‰ê· í™”í•˜ê³  ì œê³±í•œ ë’¤, ì´ë¥¼ ë‹¤ì‹œ ì œê³±ê·¼ì„ ì·¨í•œ ê°’!
- ì‘ì€ ê°’ì¼ìˆ˜ë¡ ëª¨ë¸ì˜ ì˜ˆì¸¡ì´ ë” ì •í™•í•˜ë‹¤

### 3-2. RandomForest
ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ë§ì´ ì‚¬ìš©ë˜ëŠ” ì•™ìƒë¸”(Ensemble) í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ì¤‘ í•˜ë‚˜ë¡œ, ë¶„ë¥˜(Classification)ì™€ íšŒê·€(Regression) ë¬¸ì œì— ëª¨ë‘ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ëª¨ë¸ì´ë‹¤. ëœë¤ í¬ë ˆìŠ¤íŠ¸ëŠ” ì—¬ëŸ¬ ê°œì˜ ì˜ì‚¬ê²°ì •íŠ¸ë¦¬(Decision Tree)ë¥¼ ì•™ìƒë¸”í•˜ì—¬ ë” ê°•ë ¥í•˜ê³  ì•ˆì •ì ì¸ ì˜ˆì¸¡ ëª¨ë¸ì„ êµ¬ì¶•í•˜ëŠ”ë° ì‚¬ìš©ëœë‹¤.

```python
from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor() # ë¶„ë¥˜ íŠ¸ë¦¬(default) ê°ì²´ ìƒì„±
rf.fit(X=X_train, y=y_train)

y_predict = rf.predict(X = X_test)

RMSE = mean_squared_error(y_test, y_predict)**0.5
RMSE
# RMSEê°€ 0.4ë¡œ ë‚®ì•„ì§€ëŠ” ê²ƒì„ ë³¼ ìˆ˜ìˆë‹¤
```

### 3-3. SVM
SVM(ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ )ì€ ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ì§€ë„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ì¤‘ í•˜ë‚˜ë¡œ, ì£¼ë¡œ ë¶„ë¥˜(Classification)ì™€ íšŒê·€(Regression) ë¬¸ì œì— ì‚¬ìš©ë˜ëŠ” ê°•ë ¥í•œ ëª¨ë¸. SVMì€ ë°ì´í„°ë¥¼ ê³ ì°¨ì› ê³µê°„ìœ¼ë¡œ ë§¤í•‘í•˜ì—¬ í´ë˜ìŠ¤ë¥¼ ë¶„ë¦¬í•˜ëŠ” ì´ˆí‰ë©´(hyperplane)ì„ ì°¾ëŠ” ë°©ì‹ìœ¼ë¡œ ì‘ë™í•œë‹¤.

```python
from sklearn.svm import SVR #íšŒê·€ëŠ” SVR

svr = SVR(kernel='linear', C=1.0, epsilon=0.1)
svr.fit(X_train, y_train)
y_predict = svr.predict(X_test)

RMSE = mean_squared_error(y_test, y_predict)**0.5
RMSE
# RMSEê°€ 0.70ìœ¼ë¡œ ë§¤ìš° ì»¤ì¡Œë‹¤.

from sklearn.svm import SVR #íšŒê·€ëŠ” SVR

svr = SVR(kernel='poly', C=1.0, epsilon=0.1)
svr.fit(X_train, y_train)

y_predict = svr.predict(X_test)

RMSE = mean_squared_error(y_test, y_predict)**0.5
RMSE
```

ğŸ“Œ ê²°ë¡  : RMSEê°€ ê°€ì¥ ì‘ì€ ë¹„ì„ í˜•íšŒê·€ì¼ ê²½ìš° ê°€ì¥ ë³´í—˜ë£Œ ì˜ˆì¸¡ì„ ì˜í•œë‹¤
